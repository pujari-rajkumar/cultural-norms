{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import threading\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "from transformers import *\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_emb(all_sents, tok_pooling='mean', get_cls_emb=False):\n",
    "    if len(all_sents) > 0:\n",
    "        with torch.cuda.device(0):\n",
    "            all_toks = tokenizer.batch_encode_plus(all_sents, padding='longest',\\\n",
    "                                                   add_special_tokens=True)\n",
    "            tok_tensor = torch.tensor(all_toks['input_ids']).to('cuda')\n",
    "            tok_tensor = tok_tensor[:, :512]\n",
    "            with torch.no_grad():\n",
    "                model_out = model(tok_tensor)\n",
    "                all_doc_tensor = model_out[0]\n",
    "                if get_cls_emb:\n",
    "                    all_doc_tensor = model_out[1]\n",
    "                all_doc_tensor = all_doc_tensor.to('cpu')\n",
    "            if get_cls_emb:\n",
    "                return all_doc_tensor\n",
    "            all_attn_mask = torch.tensor(all_toks['attention_mask'])\n",
    "            ret_tensor = torch.FloatTensor(all_doc_tensor.size(0), all_doc_tensor.size(-1))\n",
    "            for i in range(all_doc_tensor.size(0)):\n",
    "                slen = torch.sum(all_attn_mask[i, :])\n",
    "                if tok_pooling == 'mean':\n",
    "                    ret_tensor[i, :] = torch.mean(all_doc_tensor[i, :slen, :], dim=0)\n",
    "                elif tok_pooling == 'sum':\n",
    "                    ret_tensor[i, :] = torch.sum(all_doc_tensor[i, :slen, :], dim=0)\n",
    "                else:\n",
    "                    return 'invalid tok pooling'\n",
    "            return ret_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(all_sents, batch_size=100):\n",
    "    batches = []\n",
    "    beg = 0\n",
    "    end = batch_size\n",
    "    while beg < len(all_sents):\n",
    "        batches.append(all_sents[beg:end])\n",
    "        beg = end\n",
    "        end += batch_size\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_class = BertTokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained('hfl/chinese-bert-wwm')\n",
    "with torch.cuda.device(0):\n",
    "    with torch.no_grad():\n",
    "        model = BertModel.from_pretrained('hfl/chinese-bert-wwm',\\\n",
    "                                          output_hidden_states=False,\\\n",
    "                                          output_attentions=False)\n",
    "        model.eval()\n",
    "        model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '/homes/rpujari/scratch1_fortytwo/DARPA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = json.load(open(dir_path + 'mpdd/metadata.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue = json.load(open(dir_path + 'mpdd/dialogue.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker 左母\n",
      "utterance 那個憨女人有什麼值得送的，正鵬這個人也真是的！\n",
      "listener [{'name': '左父', 'relation': 'spouse'}]\n",
      "emotion disgust\n"
     ]
    }
   ],
   "source": [
    "for conv_id in dialogue:\n",
    "    conv = dialogue[conv_id]\n",
    "    for turn in conv:\n",
    "        for key in turn:\n",
    "            print(key, turn[key])\n",
    "        sent = turn['utterance']\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argostranslate import package, translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "package.install_from_path(dir_path + 'translate-zh_en-1_1.argosmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "installed_languages = translate.get_installed_languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English', 'Chinese']\n"
     ]
    }
   ],
   "source": [
    "print([str(lang) for lang in installed_languages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_zh_en = installed_languages[1].get_translation(installed_languages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = '那個憨女人有什麼值得送的，正鵬這個人也真是的！'\n",
    "sent2 = '哎喲，老婆子，你怎麼盡講那些不利於團結的話呢！他去送送他的同學也在情理之中嘛！'\n",
    "sent3 = '爸、媽，我回來啦！'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original translations given in the paper\n",
    "\n",
    "What is Zheng-Peng thinking? He has no need to send the silly woman home.\n",
    "Hey. My old woman. How can you say such uncoordinated words? It’s reasonable for him to send his classmate home.”\n",
    "Dad, Mom, I'm back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was true that the female stereotyped had suffice, and that the perpetrators were.\n",
      "Alexandre, How you can impose a boycott that is negative. He was sent to his fellows.\n",
      "raz, I return!\n"
     ]
    }
   ],
   "source": [
    "#Translations using argos-translate offline model\n",
    "\n",
    "print(translation_zh_en.translate(sent1))\n",
    "print(translation_zh_en.translate(sent2))\n",
    "print(translation_zh_en.translate(sent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's so good about that bitch, Jung-ho?\n",
      "Honey, why are you saying things that are not good for unity? It's also reasonable for him to send his classmates!\n",
      "Mom and Dad, I'm home!\n"
     ]
    }
   ],
   "source": [
    "#Translations using hugging-face translation model\n",
    "\n",
    "print(translate_hf(sent1))\n",
    "print(translate_hf(sent2))\n",
    "print(translate_hf(sent3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google translate webpage (API is billed and should be used via Google cloud platform)\n",
    "\n",
    "What is there for that silly woman to give, and Zhengpeng is the real one!\n",
    "Alas, old lady, how can you say all those things that are not good for unity! It makes sense for him to send off his classmates!\n",
    "Dad, Mom, I'm back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30937610d84400684142d3ca11a759c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1146.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fd5c00df82492ab5ed54cef541d612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=804677.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ca530e3b134eaf99d2d633023a0090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=806530.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd14f4e97cc949ec9ace9506af6b1d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1617902.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d306933f6f8c425aad4ab9340a5c0bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=44.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb54ac6a465d45a18231aed3a821d4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=312087009.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_hf(chinese_sent):\n",
    "    batch = tokenizer([chinese_sent], return_tensors=\"pt\")\n",
    "    generated_ids = model.generate(**batch)\n",
    "    return tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
